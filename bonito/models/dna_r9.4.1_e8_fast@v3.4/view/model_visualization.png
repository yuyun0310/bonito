digraph {
	graph [size="22.8,22.8"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140327512582160 [label="
 (20, 1, 320)" fillcolor=darkolivegreen1]
	140327512777920 [label=ViewBackward0]
	140327512996256 -> 140327512777920
	140327512996256 [label=ConstantPadNdBackward0]
	140327512996448 -> 140327512996256
	140327512996448 [label=ViewBackward0]
	140327513066608 -> 140327512996448
	140327513066608 [label=MulBackward0]
	140327513066272 -> 140327513066608
	140327513066272 [label=TanhBackward0]
	140327513066368 -> 140327513066272
	140327513066368 [label=ViewBackward0]
	140327512517984 -> 140327513066368
	140327512517984 [label=AddmmBackward0]
	140327512518080 -> 140327512517984
	140327538436832 [label="encoder.9.linear.bias
 (256)" fillcolor=lightblue]
	140327538436832 -> 140327512518080
	140327512518080 [label=AccumulateGrad]
	140327512518032 -> 140327512517984
	140327512518032 [label=ViewBackward0]
	140327512517216 -> 140327512518032
	140327512517216 [label=FlipBackward0]
	140327512518224 -> 140327512517216
	140327512518224 [label=MkldnnRnnLayerBackward0]
	140327512517168 -> 140327512518224
	140327512517168 [label=FlipBackward0]
	140327512516976 -> 140327512517168
	140327512516976 [label=MkldnnRnnLayerBackward0]
	140327512518368 -> 140327512516976
	140327512518368 [label=FlipBackward0]
	140327512518464 -> 140327512518368
	140327512518464 [label=MkldnnRnnLayerBackward0]
	140327512602032 -> 140327512518464
	140327512602032 [label=FlipBackward0]
	140327512602272 -> 140327512602032
	140327512602272 [label=MkldnnRnnLayerBackward0]
	140327512602368 -> 140327512602272
	140327512602368 [label=FlipBackward0]
	140327512602656 -> 140327512602368
	140327512602656 [label=MkldnnRnnLayerBackward0]
	140327512602752 -> 140327512602656
	140327512602752 [label=CloneBackward0]
	140327512602992 -> 140327512602752
	140327512602992 [label=FlipBackward0]
	140327512603088 -> 140327512602992
	140327512603088 [label=PermuteBackward0]
	140327512603184 -> 140327512603088
	140327512603184 [label=SiluBackward0]
	140327512603280 -> 140327512603184
	140327512603280 [label=ConvolutionBackward0]
	140327512601984 -> 140327512603280
	140327512601984 [label=SiluBackward0]
	140327512603424 -> 140327512601984
	140327512603424 [label=ConvolutionBackward0]
	140327512603520 -> 140327512603424
	140327512603520 [label=SiluBackward0]
	140327512603712 -> 140327512603520
	140327512603712 [label=ConvolutionBackward0]
	140327512603808 -> 140327512603712
	140327516979584 [label="encoder.0.conv.weight
 (4, 1, 5)" fillcolor=lightblue]
	140327516979584 -> 140327512603808
	140327512603808 [label=AccumulateGrad]
	140327512603760 -> 140327512603712
	140327516979664 [label="encoder.0.conv.bias
 (4)" fillcolor=lightblue]
	140327516979664 -> 140327512603760
	140327512603760 [label=AccumulateGrad]
	140327512603472 -> 140327512603424
	140327516979744 [label="encoder.1.conv.weight
 (16, 4, 5)" fillcolor=lightblue]
	140327516979744 -> 140327512603472
	140327512603472 [label=AccumulateGrad]
	140327512601936 -> 140327512603424
	140327516979824 [label="encoder.1.conv.bias
 (16)" fillcolor=lightblue]
	140327516979824 -> 140327512601936
	140327512601936 [label=AccumulateGrad]
	140327512603328 -> 140327512603280
	140327516979904 [label="encoder.2.conv.weight
 (128, 16, 19)" fillcolor=lightblue]
	140327516979904 -> 140327512603328
	140327512603328 [label=AccumulateGrad]
	140327512602896 -> 140327512603280
	140327516979984 [label="encoder.2.conv.bias
 (128)" fillcolor=lightblue]
	140327516979984 -> 140327512602896
	140327512602896 [label=AccumulateGrad]
	140327512602704 -> 140327512602656
	140327538436912 [label="encoder.4.rnn.weight_ih_l0
 (512, 128)" fillcolor=lightblue]
	140327538436912 -> 140327512602704
	140327512602704 [label=AccumulateGrad]
	140327512600688 -> 140327512602656
	140327516979504 [label="encoder.4.rnn.weight_hh_l0
 (512, 128)" fillcolor=lightblue]
	140327516979504 -> 140327512600688
	140327512600688 [label=AccumulateGrad]
	140327512602800 -> 140327512602656
	140327516980064 [label="encoder.4.rnn.bias_ih_l0
 (512)" fillcolor=lightblue]
	140327516980064 -> 140327512602800
	140327512602800 [label=AccumulateGrad]
	140327512602320 -> 140327512602272
	140327516980864 [label="encoder.5.rnn.weight_ih_l0
 (512, 128)" fillcolor=lightblue]
	140327516980864 -> 140327512602320
	140327512602320 [label=AccumulateGrad]
	140327512602176 -> 140327512602272
	140327516980784 [label="encoder.5.rnn.weight_hh_l0
 (512, 128)" fillcolor=lightblue]
	140327516980784 -> 140327512602176
	140327512602176 [label=AccumulateGrad]
	140327512602416 -> 140327512602272
	140327516980464 [label="encoder.5.rnn.bias_ih_l0
 (512)" fillcolor=lightblue]
	140327516980464 -> 140327512602416
	140327512602416 [label=AccumulateGrad]
	140327512600736 -> 140327512518464
	140327516981184 [label="encoder.6.rnn.weight_ih_l0
 (512, 128)" fillcolor=lightblue]
	140327516981184 -> 140327512600736
	140327512600736 [label=AccumulateGrad]
	140327512600640 -> 140327512518464
	140327516981424 [label="encoder.6.rnn.weight_hh_l0
 (512, 128)" fillcolor=lightblue]
	140327516981424 -> 140327512600640
	140327512600640 [label=AccumulateGrad]
	140327512602080 -> 140327512518464
	140327516981344 [label="encoder.6.rnn.bias_ih_l0
 (512)" fillcolor=lightblue]
	140327516981344 -> 140327512602080
	140327512602080 [label=AccumulateGrad]
	140327512516496 -> 140327512516976
	140327516981824 [label="encoder.7.rnn.weight_ih_l0
 (512, 128)" fillcolor=lightblue]
	140327516981824 -> 140327512516496
	140327512516496 [label=AccumulateGrad]
	140327512517264 -> 140327512516976
	140327516982064 [label="encoder.7.rnn.weight_hh_l0
 (512, 128)" fillcolor=lightblue]
	140327516982064 -> 140327512517264
	140327512517264 [label=AccumulateGrad]
	140327512518416 -> 140327512516976
	140327516981984 [label="encoder.7.rnn.bias_ih_l0
 (512)" fillcolor=lightblue]
	140327516981984 -> 140327512518416
	140327512518416 [label=AccumulateGrad]
	140327512518272 -> 140327512518224
	140327516982464 [label="encoder.8.rnn.weight_ih_l0
 (512, 128)" fillcolor=lightblue]
	140327516982464 -> 140327512518272
	140327512518272 [label=AccumulateGrad]
	140327512517600 -> 140327512518224
	140327516982704 [label="encoder.8.rnn.weight_hh_l0
 (512, 128)" fillcolor=lightblue]
	140327516982704 -> 140327512517600
	140327512517600 [label=AccumulateGrad]
	140327512517312 -> 140327512518224
	140327516982624 [label="encoder.8.rnn.bias_ih_l0
 (512)" fillcolor=lightblue]
	140327516982624 -> 140327512517312
	140327512517312 [label=AccumulateGrad]
	140327512517504 -> 140327512517984
	140327512517504 [label=TBackward0]
	140327512518320 -> 140327512517504
	140327545734464 [label="encoder.9.linear.weight
 (256, 128)" fillcolor=lightblue]
	140327545734464 -> 140327512518320
	140327512518320 [label=AccumulateGrad]
	140327512777920 -> 140327512582160
	140327512582240 [label="
 (20, 1, 64, 5)" fillcolor=darkolivegreen3]
	140327512996256 -> 140327512582240
	140327512582240 -> 140327512582160 [style=dotted]
}
