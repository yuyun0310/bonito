digraph {
	graph [size="22.8,22.8"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	139880816398240 [label="
 (20, 1, 320)" fillcolor=darkolivegreen1]
	139880811744512 [label=ViewBackward0]
	139880811744272 -> 139880811744512
	139880811744272 [label=ConstantPadNdBackward0]
	139880811746480 -> 139880811744272
	139880811746480 [label=ViewBackward0]
	139880811746528 -> 139880811746480
	139880811746528 [label=MulBackward0]
	139880811746624 -> 139880811746528
	139880811746624 [label=TanhBackward0]
	139880811746720 -> 139880811746624
	139880811746720 [label=ViewBackward0]
	139880811746816 -> 139880811746720
	139880811746816 [label=AddmmBackward0]
	139880811746912 -> 139880811746816
	139880815707872 [label="encoder.9.linear.bias
 (256)" fillcolor=lightblue]
	139880815707872 -> 139880811746912
	139880811746912 [label=AccumulateGrad]
	139880811746864 -> 139880811746816
	139880811746864 [label=ViewBackward0]
	139880811747008 -> 139880811746864
	139880811747008 [label=FlipBackward0]
	139880811747200 -> 139880811747008
	139880811747200 [label=MkldnnRnnLayerBackward0]
	139880811747296 -> 139880811747200
	139880811747296 [label=FlipBackward0]
	139880811747536 -> 139880811747296
	139880811747536 [label=MkldnnRnnLayerBackward0]
	139880811747632 -> 139880811747536
	139880811747632 [label=FlipBackward0]
	139880811747872 -> 139880811747632
	139880811747872 [label=MkldnnRnnLayerBackward0]
	139880811747968 -> 139880811747872
	139880811747968 [label=FlipBackward0]
	139880811748208 -> 139880811747968
	139880811748208 [label=MkldnnRnnLayerBackward0]
	139880811748304 -> 139880811748208
	139880811748304 [label=FlipBackward0]
	139880811748544 -> 139880811748304
	139880811748544 [label=MkldnnRnnLayerBackward0]
	139880811748640 -> 139880811748544
	139880811748640 [label=CloneBackward0]
	139880811748880 -> 139880811748640
	139880811748880 [label=FlipBackward0]
	139880811748976 -> 139880811748880
	139880811748976 [label=PermuteBackward0]
	139880811749072 -> 139880811748976
	139880811749072 [label=SiluBackward0]
	139880811749168 -> 139880811749072
	139880811749168 [label=ConvolutionBackward0]
	139880811749264 -> 139880811749168
	139880811749264 [label=SiluBackward0]
	139880811749456 -> 139880811749264
	139880811749456 [label=ConvolutionBackward0]
	139880811749552 -> 139880811749456
	139880811749552 [label=SiluBackward0]
	139880811749744 -> 139880811749552
	139880811749744 [label=ConvolutionBackward0]
	139880811749840 -> 139880811749744
	139880841158064 [label="encoder.0.conv.weight
 (4, 1, 5)" fillcolor=lightblue]
	139880841158064 -> 139880811749840
	139880811749840 [label=AccumulateGrad]
	139880811749792 -> 139880811749744
	139880841153344 [label="encoder.0.conv.bias
 (4)" fillcolor=lightblue]
	139880841153344 -> 139880811749792
	139880811749792 [label=AccumulateGrad]
	139880811749504 -> 139880811749456
	139880815431504 [label="encoder.1.conv.weight
 (16, 4, 5)" fillcolor=lightblue]
	139880815431504 -> 139880811749504
	139880811749504 [label=AccumulateGrad]
	139880811749360 -> 139880811749456
	139880841152144 [label="encoder.1.conv.bias
 (16)" fillcolor=lightblue]
	139880841152144 -> 139880811749360
	139880811749360 [label=AccumulateGrad]
	139880811749216 -> 139880811749168
	139880841156064 [label="encoder.2.conv.weight
 (128, 16, 19)" fillcolor=lightblue]
	139880841156064 -> 139880811749216
	139880811749216 [label=AccumulateGrad]
	139880811748784 -> 139880811749168
	139880815655776 [label="encoder.2.conv.bias
 (128)" fillcolor=lightblue]
	139880815655776 -> 139880811748784
	139880811748784 [label=AccumulateGrad]
	139880811748592 -> 139880811748544
	139880849702448 [label="encoder.4.rnn.weight_ih_l0
 (512, 128)" fillcolor=lightblue]
	139880849702448 -> 139880811748592
	139880811748592 [label=AccumulateGrad]
	139880811748448 -> 139880811748544
	139880849849664 [label="encoder.4.rnn.weight_hh_l0
 (512, 128)" fillcolor=lightblue]
	139880849849664 -> 139880811748448
	139880811748448 [label=AccumulateGrad]
	139880811748688 -> 139880811748544
	139880815436064 [label="encoder.4.rnn.bias_ih_l0
 (512)" fillcolor=lightblue]
	139880815436064 -> 139880811748688
	139880811748688 [label=AccumulateGrad]
	139880811748256 -> 139880811748208
	139880815434224 [label="encoder.5.rnn.weight_ih_l0
 (512, 128)" fillcolor=lightblue]
	139880815434224 -> 139880811748256
	139880811748256 [label=AccumulateGrad]
	139880811748112 -> 139880811748208
	139880815656176 [label="encoder.5.rnn.weight_hh_l0
 (512, 128)" fillcolor=lightblue]
	139880815656176 -> 139880811748112
	139880811748112 [label=AccumulateGrad]
	139880811748352 -> 139880811748208
	139880815656496 [label="encoder.5.rnn.bias_ih_l0
 (512)" fillcolor=lightblue]
	139880815656496 -> 139880811748352
	139880811748352 [label=AccumulateGrad]
	139880811747920 -> 139880811747872
	139880815656736 [label="encoder.6.rnn.weight_ih_l0
 (512, 128)" fillcolor=lightblue]
	139880815656736 -> 139880811747920
	139880811747920 [label=AccumulateGrad]
	139880811747776 -> 139880811747872
	139880815656896 [label="encoder.6.rnn.weight_hh_l0
 (512, 128)" fillcolor=lightblue]
	139880815656896 -> 139880811747776
	139880811747776 [label=AccumulateGrad]
	139880811748016 -> 139880811747872
	139880815656816 [label="encoder.6.rnn.bias_ih_l0
 (512)" fillcolor=lightblue]
	139880815656816 -> 139880811748016
	139880811748016 [label=AccumulateGrad]
	139880811747584 -> 139880811747536
	139880815706592 [label="encoder.7.rnn.weight_ih_l0
 (512, 128)" fillcolor=lightblue]
	139880815706592 -> 139880811747584
	139880811747584 [label=AccumulateGrad]
	139880811747440 -> 139880811747536
	139880815706832 [label="encoder.7.rnn.weight_hh_l0
 (512, 128)" fillcolor=lightblue]
	139880815706832 -> 139880811747440
	139880811747440 [label=AccumulateGrad]
	139880811747680 -> 139880811747536
	139880815706752 [label="encoder.7.rnn.bias_ih_l0
 (512)" fillcolor=lightblue]
	139880815706752 -> 139880811747680
	139880811747680 [label=AccumulateGrad]
	139880811747248 -> 139880811747200
	139880815707232 [label="encoder.8.rnn.weight_ih_l0
 (512, 128)" fillcolor=lightblue]
	139880815707232 -> 139880811747248
	139880811747248 [label=AccumulateGrad]
	139880811747104 -> 139880811747200
	139880815707472 [label="encoder.8.rnn.weight_hh_l0
 (512, 128)" fillcolor=lightblue]
	139880815707472 -> 139880811747104
	139880811747104 [label=AccumulateGrad]
	139880811747344 -> 139880811747200
	139880815707392 [label="encoder.8.rnn.bias_ih_l0
 (512)" fillcolor=lightblue]
	139880815707392 -> 139880811747344
	139880811747344 [label=AccumulateGrad]
	139880811744320 -> 139880811746816
	139880811744320 [label=TBackward0]
	139880811747392 -> 139880811744320
	139880841156144 [label="encoder.9.linear.weight
 (256, 128)" fillcolor=lightblue]
	139880841156144 -> 139880811747392
	139880811747392 [label=AccumulateGrad]
	139880811744512 -> 139880816398240
	139880811441888 [label="
 (20, 1, 64, 5)" fillcolor=darkolivegreen3]
	139880811744272 -> 139880811441888
	139880811441888 -> 139880816398240 [style=dotted]
}
